{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTadl76QlLRQ",
        "outputId": "fb57ab38-099f-4dd1-caa6-c1d95cf497cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex = 'European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices'"
      ],
      "metadata": {
        "id": "2YwPZXt7lnPw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(sent):\n",
        "    sent = nltk.word_tokenize(sent)\n",
        "    sent = nltk.pos_tag(sent)\n",
        "    return sent"
      ],
      "metadata": {
        "id": "s1EhfuCdlrTW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "sent = preprocess(ex)\n",
        "sent\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYtaWHfmluje",
        "outputId": "e8c0e96e-50f7-41e7-e691-771ab04a5dbb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('European', 'JJ'),\n",
              " ('authorities', 'NNS'),\n",
              " ('fined', 'VBD'),\n",
              " ('Google', 'NNP'),\n",
              " ('a', 'DT'),\n",
              " ('record', 'NN'),\n",
              " ('$', '$'),\n",
              " ('5.1', 'CD'),\n",
              " ('billion', 'CD'),\n",
              " ('on', 'IN'),\n",
              " ('Wednesday', 'NNP'),\n",
              " ('for', 'IN'),\n",
              " ('abusing', 'VBG'),\n",
              " ('its', 'PRP$'),\n",
              " ('power', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('mobile', 'JJ'),\n",
              " ('phone', 'NN'),\n",
              " ('market', 'NN'),\n",
              " ('and', 'CC'),\n",
              " ('ordered', 'VBD'),\n",
              " ('the', 'DT'),\n",
              " ('company', 'NN'),\n",
              " ('to', 'TO'),\n",
              " ('alter', 'VB'),\n",
              " ('its', 'PRP$'),\n",
              " ('practices', 'NNS')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = 'NP: {<DT>?<JJ>*<NN>}'"
      ],
      "metadata": {
        "id": "htj2ySDPlv82"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp = nltk.RegexpParser(pattern)\n",
        "cs = cp.parse(sent)\n",
        "print(cs)"
      ],
      "metadata": {
        "id": "zgLbYTlHl_pu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cb6aa07-6c2c-4b0b-e85b-6c239e6daa22"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  European/JJ\n",
            "  authorities/NNS\n",
            "  fined/VBD\n",
            "  Google/NNP\n",
            "  (NP a/DT record/NN)\n",
            "  $/$\n",
            "  5.1/CD\n",
            "  billion/CD\n",
            "  on/IN\n",
            "  Wednesday/NNP\n",
            "  for/IN\n",
            "  abusing/VBG\n",
            "  its/PRP$\n",
            "  (NP power/NN)\n",
            "  in/IN\n",
            "  (NP the/DT mobile/JJ phone/NN)\n",
            "  (NP market/NN)\n",
            "  and/CC\n",
            "  ordered/VBD\n",
            "  (NP the/DT company/NN)\n",
            "  to/TO\n",
            "  alter/VB\n",
            "  its/PRP$\n",
            "  practices/NNS)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.chunk import conlltags2tree, tree2conlltags\n",
        "from pprint import pprint\n",
        "from nltk.chunk import ne_chunk\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import conll2000\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "iob_tagged = tree2conlltags(cs)\n",
        "pprint(iob_tagged)"
      ],
      "metadata": {
        "id": "qNfCYiq5mBrm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59e2cd5f-cedc-4c14-eb80-b17ae3545f1a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('European', 'JJ', 'O'),\n",
            " ('authorities', 'NNS', 'O'),\n",
            " ('fined', 'VBD', 'O'),\n",
            " ('Google', 'NNP', 'O'),\n",
            " ('a', 'DT', 'B-NP'),\n",
            " ('record', 'NN', 'I-NP'),\n",
            " ('$', '$', 'O'),\n",
            " ('5.1', 'CD', 'O'),\n",
            " ('billion', 'CD', 'O'),\n",
            " ('on', 'IN', 'O'),\n",
            " ('Wednesday', 'NNP', 'O'),\n",
            " ('for', 'IN', 'O'),\n",
            " ('abusing', 'VBG', 'O'),\n",
            " ('its', 'PRP$', 'O'),\n",
            " ('power', 'NN', 'B-NP'),\n",
            " ('in', 'IN', 'O'),\n",
            " ('the', 'DT', 'B-NP'),\n",
            " ('mobile', 'JJ', 'I-NP'),\n",
            " ('phone', 'NN', 'I-NP'),\n",
            " ('market', 'NN', 'B-NP'),\n",
            " ('and', 'CC', 'O'),\n",
            " ('ordered', 'VBD', 'O'),\n",
            " ('the', 'DT', 'B-NP'),\n",
            " ('company', 'NN', 'I-NP'),\n",
            " ('to', 'TO', 'O'),\n",
            " ('alter', 'VB', 'O'),\n",
            " ('its', 'PRP$', 'O'),\n",
            " ('practices', 'NNS', 'O')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ne_tree = ne_chunk(pos_tag(word_tokenize(ex)))\n",
        "print(ne_tree)"
      ],
      "metadata": {
        "id": "0O2DnZq0mDju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdac0f68-b618-4933-9288-3b899fcc3995"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (GPE European/JJ)\n",
            "  authorities/NNS\n",
            "  fined/VBD\n",
            "  (PERSON Google/NNP)\n",
            "  a/DT\n",
            "  record/NN\n",
            "  $/$\n",
            "  5.1/CD\n",
            "  billion/CD\n",
            "  on/IN\n",
            "  Wednesday/NNP\n",
            "  for/IN\n",
            "  abusing/VBG\n",
            "  its/PRP$\n",
            "  power/NN\n",
            "  in/IN\n",
            "  the/DT\n",
            "  mobile/JJ\n",
            "  phone/NN\n",
            "  market/NN\n",
            "  and/CC\n",
            "  ordered/VBD\n",
            "  the/DT\n",
            "  company/NN\n",
            "  to/TO\n",
            "  alter/VB\n",
            "  its/PRP$\n",
            "  practices/NNS)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "from collections import Counter\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()"
      ],
      "metadata": {
        "id": "TZqF5cqnmINe"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp('European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices')\n",
        "pprint([(X.text, X.label_) for X in doc.ents])"
      ],
      "metadata": {
        "id": "WsFgeGIDmLjA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faa5754d-39e2-4037-bfdf-4161755e4e1b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('European', 'NORP'),\n",
            " ('Google', 'ORG'),\n",
            " ('$5.1 billion', 'MONEY'),\n",
            " ('Wednesday', 'DATE')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint([(X, X.ent_iob_, X.ent_type_) for X in doc])"
      ],
      "metadata": {
        "id": "Egto8nxZmLm1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa6cb299-c3c7-4a3e-fa0c-717de123d749"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(European, 'B', 'NORP'),\n",
            " (authorities, 'O', ''),\n",
            " (fined, 'O', ''),\n",
            " (Google, 'B', 'ORG'),\n",
            " (a, 'O', ''),\n",
            " (record, 'O', ''),\n",
            " ($, 'B', 'MONEY'),\n",
            " (5.1, 'I', 'MONEY'),\n",
            " (billion, 'I', 'MONEY'),\n",
            " (on, 'O', ''),\n",
            " (Wednesday, 'B', 'DATE'),\n",
            " (for, 'O', ''),\n",
            " (abusing, 'O', ''),\n",
            " (its, 'O', ''),\n",
            " (power, 'O', ''),\n",
            " (in, 'O', ''),\n",
            " (the, 'O', ''),\n",
            " (mobile, 'O', ''),\n",
            " (phone, 'O', ''),\n",
            " (market, 'O', ''),\n",
            " (and, 'O', ''),\n",
            " (ordered, 'O', ''),\n",
            " (the, 'O', ''),\n",
            " (company, 'O', ''),\n",
            " (to, 'O', ''),\n",
            " (alter, 'O', ''),\n",
            " (its, 'O', ''),\n",
            " (practices, 'O', '')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import re\n",
        "def url_to_string(url):\n",
        "    res = requests.get(url)\n",
        "    html = res.text\n",
        "    soup = BeautifulSoup(html, 'html5lib')\n",
        "    for script in soup([\"script\", \"style\", 'aside']):\n",
        "        script.extract()\n",
        "    return \" \".join(re.split(r'[\\n\\t]+', soup.get_text()))\n",
        "# ny_bb = url_to_string('https://www.nytimes.com/2018/08/13/us/politics/peter-strzok-fired-fbi.html?hp&action=click&pgtype=Homepage&clickSource=story-heading&module=first-column-region&region=top-news&WT.nav=top-news')\n",
        "ny_bb = url_to_string('https://aeon.co/essays/a-rebel-spirit-and-an-artists-eye-russell-pages-landscape-design')\n",
        "article = nlp(ny_bb)\n",
        "len(article.ents)"
      ],
      "metadata": {
        "id": "PMEfEETpmLpk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e148d8d0-6a92-4748-ad43-5fcbd9536f84"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "349"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [x.label_ for x in article.ents]\n",
        "Counter(labels)"
      ],
      "metadata": {
        "id": "De-p9ObomWPn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "954ec31c-9d3d-45d1-b27e-13d4c89178a0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'PERSON': 118,\n",
              "         'ORG': 50,\n",
              "         'GPE': 59,\n",
              "         'DATE': 46,\n",
              "         'LOC': 10,\n",
              "         'WORK_OF_ART': 3,\n",
              "         'NORP': 35,\n",
              "         'FAC': 6,\n",
              "         'LANGUAGE': 3,\n",
              "         'CARDINAL': 14,\n",
              "         'ORDINAL': 4,\n",
              "         'PRODUCT': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "items = [x.text for x in article.ents]\n",
        "Counter(items).most_common(3)"
      ],
      "metadata": {
        "id": "uS5TRiwwmanN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e4d9994-aa4d-4972-8154-4b3357f8bc91"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Page', 70), ('England', 8), ('French', 8)]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [x for x in article.sents]\n",
        "print(sentences[10])"
      ],
      "metadata": {
        "id": "TdbsvN_AmaqS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3533561f-6a5a-42f9-be38-6f1ee8843a64"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fred Whitsey, the longtime gardening correspondent for The Daily Telegraph, asked after Pageâ€™s death.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Named Entity Recognition (NER) is a natural language processing task that involves identifying and classifying entities, such as names of people, places, organizations, dates, and more, within text. Here's a step-wise guide for NER with step counts:\n",
        "\n",
        "**Step 1: Preprocessing**\n",
        "\n",
        "1. **Text Tokenization:**\n",
        "   Split the input text into individual words or tokens.\n",
        "\n",
        "2. **Part-of-Speech Tagging (Optional):**\n",
        "   You can perform part-of-speech tagging to identify the grammatical category of each word in the text. This can help in disambiguating entity types.\n",
        "\n",
        "**Step 2: Named Entity Recognition**\n",
        "\n",
        "3. **Load or Train NER Model:**\n",
        "   Choose an NER model or train your own. There are various pre-trained models available for NER, such as spaCy, NLTK, and Stanford NER. If you're training your own model, you'll need labeled data with entity annotations.\n",
        "\n",
        "4. **Apply NER Model:**\n",
        "   Pass the tokenized text through the NER model to identify entities. The model will return a list of entities with their types and positions in the text.\n",
        "\n",
        "**Step 3: Post-processing**\n",
        "\n",
        "5. **Entity Type Classification (Optional):**\n",
        "   If your NER model doesn't classify entity types, you can use rules or additional models to categorize the recognized entities (e.g., person, location, organization).\n",
        "\n",
        "6. **Entity Post-Processing (Optional):**\n",
        "   Apply post-processing rules to improve entity recognition. This may involve merging adjacent tokens into a single entity, handling abbreviations, or resolving entity coreference.\n",
        "\n",
        "**Step 4: Output and Use**\n",
        "\n",
        "7. **Retrieve NER Results:**\n",
        "   Extract the identified entities and their types from the output of the NER model.\n",
        "\n",
        "8. **Utilize NER Results:**\n",
        "   Use the recognized entities in various downstream applications, such as information retrieval, text summarization, or knowledge graph construction.\n",
        "\n"
      ],
      "metadata": {
        "id": "QO74go838LEm"
      }
    }
  ]
}